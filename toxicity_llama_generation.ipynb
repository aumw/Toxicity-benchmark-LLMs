{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BShmxKPZEPyk"
      },
      "outputs": [],
      "source": [
        "!pip install transformers torch huggingface_hub accelerate -q\n",
        "import transformers\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "MFpazlN9EY5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "toxicity_prompts = load_dataset(\"allenai/real-toxicity-prompts\", split=\"train\")"
      ],
      "metadata": {
        "id": "-VkhOpGbEbKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "toxicity_prompts"
      ],
      "metadata": {
        "id": "E6huv2brEe1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def get_prompts(dataset, num=200):\n",
        "    # Filter for prompts with toxicity > 0.5\n",
        "    toxic_beginnings = [p for p in dataset if p['prompt']['toxicity'] is not None and p['prompt']['toxicity'] > 0.5]\n",
        "    non_toxic_beginnings = [p for p in dataset if p['prompt']['toxicity'] is not None and p['prompt']['toxicity'] < 0.5]\n",
        "\n",
        "    random.seed(42)\n",
        "    return random.sample(toxic_beginnings, num), random.sample(non_toxic_beginnings, num)\n",
        "\n",
        "# toxic_samples, non_toxic_samples = get_prompts(toxicity_prompts)\n",
        "# for sample in non_toxic_samples:\n",
        "#     print(sample['prompt']['text'])"
      ],
      "metadata": {
        "id": "ILpMphh0EiwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "toxic_sample, non_toxic_sample = get_prompts(toxicity_prompts)\n",
        "toxic_prompts = [p['prompt']['text'] for p in toxic_sample]\n",
        "non_toxic_prompts = [p['prompt']['text'] for p in non_toxic_sample]"
      ],
      "metadata": {
        "id": "sdDEC96DEmxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
        "\n",
        "pipeline = transformers.pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "terminators = [\n",
        "    pipeline.tokenizer.eos_token_id,\n",
        "    pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
        "]"
      ],
      "metadata": {
        "id": "fmnSSFbgE1x1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model_continuations(toxic_prompts):\n",
        "    model_continuations = []\n",
        "    i = 0\n",
        "    for prompt in toxic_prompts:\n",
        "        print(i)\n",
        "        i += 1\n",
        "\n",
        "        generation = pipeline([prompt], max_new_tokens=20, do_sample=False, pad_token_id=50256, eos_token_id=terminators)\n",
        "        #print(generation[0][0]['generated_text'])\n",
        "        continuation = generation[0][0]['generated_text'].replace(prompt,'')\n",
        "\n",
        "        model_continuations.append(continuation)\n",
        "\n",
        "    return model_continuations\n",
        "\n"
      ],
      "metadata": {
        "id": "6f74ix0pEpYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llama_continuations_non_toxic = get_model_continuations(df['non_toxic_prompts'].to_list())\n",
        "llama_continuations_toxic = get_model_continuations(df['toxic_prompts'].to_list())"
      ],
      "metadata": {
        "id": "kB77mxmOEsoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame({'toxic_prompts':toxic_prompts, 'non_toxic_prompts':non_toxic_prompts, 'llama_continuations_toxic':llama_continuations_toxic, 'gpt_continuations_non_toxic':llama_continuations_non_toxic})"
      ],
      "metadata": {
        "id": "S1l6EU32Eyqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('toxic_continuations_llama.csv')"
      ],
      "metadata": {
        "id": "yj3vEaNPE6pm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}